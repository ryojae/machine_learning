{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#문제"
      ],
      "metadata": {
        "id": "DQCD3KkF6kLt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RRzPsvzrg5G"
      },
      "source": [
        "##1. 매개변수 갱신"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문제 1**\n",
        "\n",
        "확률적 경사 하강법(SGD)에서 매개변수 갱신 방법을 나타내는 수식은 무엇인가요?\n",
        "\n"
      ],
      "metadata": {
        "id": "HhcwDOv5nO6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) $W_{t+1} = W_t -  𝜂 ⋅ \\frac{∂L}{∂W_t}$  정답**\n",
        "\n",
        "2) $W_{t+1} = W_t +  𝜂 ⋅ \\frac{∂L}{∂W_t}$\n",
        "\n",
        "3) $W_{t+1} = W_t -  𝜂 ⋅ W_t$\n",
        "\n",
        "4) $W_{t+1} = W_t +  𝜂 ⋅ W_t$\n"
      ],
      "metadata": {
        "id": "Myox8g1xaG5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문제 2**\n",
        "\n",
        "모멘텀(momentum) 방법이 확률적 경사 하강법(SGD)과 다른 점으로 올바른 것은 무엇인가요?"
      ],
      "metadata": {
        "id": "LKEpTZRlnffl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1) 학습률을 동적으로 조정한다.\n",
        "\n",
        "**2) 기울기 방향으로 힘을 받아 속도가 가속된다.**\n",
        "\n",
        "3) 더 작은 배치 크기를 사용한다.\n",
        "\n",
        "4) 매개변수 갱신 시 이전의 가중치를 무시한다."
      ],
      "metadata": {
        "id": "TKzEbWnVaSLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 가중치 초기화\n"
      ],
      "metadata": {
        "id": "4W_7GzGznk4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문제 3**\n",
        "\n",
        "가중치를 0으로 초기화하면 안 되는 이유로 가장 적절한 것은 무엇인가요?"
      ],
      "metadata": {
        "id": "UyL3jtT3ni9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 학습 속도가 너무 빨라질 수 있기 때문에\n",
        "\n",
        "**2) 모든 뉴런이 동일하게 업데이트되어 학습이 제대로 이루어지지 않기 때문에**\n",
        "\n",
        "3) 메모리 사용량이 증가하기 때문에\n",
        "\n",
        "4) 학습 과정에서 가중치가 발산하기 때문에"
      ],
      "metadata": {
        "id": "DvcoSedVarr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문제 4**\n",
        "\n",
        "Xavier 초기화와 He 초기화의 차이에 대한 설명으로 올바른 것은 무엇인가요?"
      ],
      "metadata": {
        "id": "a_8my5sTnoDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Xavier 초기화는 ReLU 활성화 함수에 적합하다.\n",
        "\n",
        "**2) He 초기화는 ReLU와 같은 활성화 함수에 더 적합하다.**\n",
        "\n",
        "3) Xavier 초기화는 주로 딥러닝의 출력층에 사용된다.\n",
        "\n",
        "4) He 초기화는 모든 유형의 신경망 층에 사용된다."
      ],
      "metadata": {
        "id": "LC3AnxoGax2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 배치 정규화"
      ],
      "metadata": {
        "id": "UGpy7xD4qRKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문제 5**\n",
        "\n",
        "배치 정규화(Batch Normalization)의 주된 효과로 올바른 것은 무엇인가요?"
      ],
      "metadata": {
        "id": "1Z_fPXd6nr39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 과적합을 방지한다.\n",
        "\n",
        "**2) 활성화 함수의 선택에 상관없이 학습 속도를 향상시킨다.**\n",
        "\n",
        "3) 입력 데이터를 정규화하여 학습을 빠르게 한다.\n",
        "\n",
        "4) 입력 데이터의 차원을 줄인다."
      ],
      "metadata": {
        "id": "0I3H4eega7fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문제 6**\n",
        "\n",
        "배치 정규화에서 학습 시와 추론 시의 차이점에 대한 설명으로 올바른 것은 무엇인가요?\n"
      ],
      "metadata": {
        "id": "hHP31VR2nv2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1) 학습 시에는 정규화를 사용하고, 추론 시에는 사용하지 않는다.\n",
        "\n",
        "**2) 학습 시에는 배치 평균과 분산을 사용하고, 추론 시에는 전체 데이터셋의 평균과 분산을 사용한다.**\n",
        "\n",
        "3) 학습 시에는 활성화 함수를 사용하지 않고, 추론 시에만 사용한다.\n",
        "\n",
        "4) 학습 시에는 드롭아웃과 함께 사용하고, 추론 시에는 드롭아웃을 제거한다.\n"
      ],
      "metadata": {
        "id": "tMaemZMkqiJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 바른 학습을 위해"
      ],
      "metadata": {
        "id": "HW1WDKpDqlJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문제 7**\n",
        "\n",
        "과적합을 방지하는 드롭아웃(Dropout)의 원리에 대한 설명으로 올바른 것은 무엇인가요?\n"
      ],
      "metadata": {
        "id": "Em5TctWYnzA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 뉴런의 가중치를 임의로 0으로 설정하여 학습을 방해한다.\n",
        "\n",
        "**2) 뉴런을 임의로 비활성화하여 다양한 뉴런을 학습시킨다.**\n",
        "\n",
        "3) 학습 중 일부 데이터를 임의로 제거하여 모델의 일반화를 향상시킨다.\n",
        "\n",
        "4) 활성화 함수의 출력을 0으로 변경하여 과적합을 방지한다."
      ],
      "metadata": {
        "id": "JhTQdmdrbQ4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문제 8**\n",
        "\n",
        "가중치 감소(Weight Decay)의 주요 목적은 무엇인가요?"
      ],
      "metadata": {
        "id": "KVXWmi5qn1vA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 학습 속도를 증가시키기 위해\n",
        "\n",
        "**2) 과적합(overfitting)을 방지하기 위해**\n",
        "\n",
        "3) 가중치의 크기를 증가시키기 위해\n",
        "\n",
        "4) 활성화 함수를 정규화하기 위해"
      ],
      "metadata": {
        "id": "PIP-iRA6b6JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 적절한 하이퍼파라미터 값 찾기"
      ],
      "metadata": {
        "id": "MsqE1nTRq30z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문제 9**\n",
        "\n",
        "하이퍼파라미터 튜닝에서 그리드 서치(Grid Search)와 랜덤 서치(Random Search)의 차이점으로 올바른 것은 무엇인가요?"
      ],
      "metadata": {
        "id": "Ur-B_jNDn4Se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 그리드 서치는 무작위로 하이퍼파라미터 값을 선택한다.\n",
        "\n",
        "2) 랜덤 서치는 하이퍼파라미터 값을 고정된 간격으로 선택한다.\n",
        "\n",
        "**3) 그리드 서치는 모든 조합을 탐색하고, 랜덤 서치는 무작위로 선택한다.**\n",
        "\n",
        "4) 그리드 서치는 작은 하이퍼파라미터 공간에서만 작동한다."
      ],
      "metadata": {
        "id": "7C_yjSidcI5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**문제 10**\n",
        "\n",
        "학습률(Learning Rate)이 너무 클 때 발생할 수 있는 문제로 올바른 것은 무엇인가요?"
      ],
      "metadata": {
        "id": "PA8ARwDQn6XD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 학습이 느려진다.\n",
        "\n",
        "2) 기울기가 0이 되어 학습이 중단된다.\n",
        "\n",
        "**3) 손실 함수의 값이 진동하거나 발산할 수 있다.**\n",
        "\n",
        "4) 과적합이 심화된다."
      ],
      "metadata": {
        "id": "Ebdr7rmccLyb"
      }
    }
  ]
}