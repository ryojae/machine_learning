{"cells":[{"cell_type":"markdown","metadata":{"id":"nmq_ohyPB_im"},"source":["# 답안 작성 방법\n","\n","아래 이미지에서 \"더블클릭 또는 Enter키를 눌러 수정\"을 누르신후 해당 창에 답을 적으시면 됩니다.\n","\n","![image](https://github.com/user-attachments/assets/2aa2ff05-fb0e-4f00-a121-78afeaad4f09)\n","\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"JiAFUXF2DadY"},"source":["# 05차시 과제"]},{"cell_type":"markdown","metadata":{"id":"0aCZcWB4--lq"},"source":["### Logistic Regression이 무엇인지 서술하시오."]},{"cell_type":"markdown","metadata":{"id":"IXinXk5L--lq"},"source":["이진 분류를 해주는 모델로 시그모이드 함수를 통해 입력값을 확률로 변환하고, 이 확률을 바탕으로 데이터를 두 개의 클래스 중 하나로 부뉴해준다."]},{"cell_type":"markdown","metadata":{"id":"mUHb2YzQ--lq"},"source":["### Logistic Regression을 사용할 수 있는 사례를 5가지만 서술하시오."]},{"cell_type":"markdown","metadata":{"id":"nXQ1UqPi--lq"},"source":["- 질병진단\n","- 사망여부\n","- 스팸 이메일 분류\n","- 시험 통과\n","- 마케팅 성공"]},{"cell_type":"markdown","metadata":{"id":"yyqFi7EC--lq"},"source":["### 제시된 코드에 주석을 작성하고 조건에 맞추어 빈칸(***)를 채워라.\n","\n","**조건**\n","\n","1. Optimizer는 Adam을 사용하라\n","2. learning rate는 0.001을 사용하라\n","3. loss function은 MSE를 사용하라.\n","4. 에포크는 100으로 설정하라."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qsuceBad--lr","executionInfo":{"status":"ok","timestamp":1724144838305,"user_tz":-540,"elapsed":817,"user":{"displayName":"호재류","userId":"13851742628565243579"}}},"outputs":[],"source":["import torch\n","\n","model = torch.nn.Linear(2, 1)\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = torch.nn.MSELoss()\n","\n","x_data = torch.Tensor([[1.0, 1.5], [2.0, 3.0], [2.0, 4.0]])\n","y_data = torch.Tensor([[2.0], [4.0], [6.0]])\n","\n","for epoch in range(100):\n","    y_pred = model(x_data)\n","\n","    loss = criterion(y_pred, y_data)\n","\n","    optim.zero_grad()\n","    loss.backward()\n","    optim.step()"]},{"cell_type":"markdown","metadata":{"id":"BNo52hhm--lr"},"source":["### 역전파(Back-propagation)이 무엇인지 서술하시오."]},{"cell_type":"markdown","metadata":{"id":"9n4lUufC--ls"},"source":["역전파란 순전파를 통한 출력을 기준으로 오차를 계산하고 그 오차를 역으로 전파하여 각 층의 가중치와 편향을 조정하는 것을 의미한다."]},{"cell_type":"markdown","metadata":{"id":"OsoAddPM--ls"},"source":["### 아래 제공된 수식은 sigmoid 함수이다. z값이 양의 무한대로 발산할때와 음의 무한대로 발산할 때 각각 sigmoid 값이 어떻게 변하는지 서술하라.\n","\n","\n","$$\n","\n","\\sigma(z) = {1 \\over 1+e^{-z}}\n","\n","$$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ty0oKrmj--ls"},"source":["양의 무한대로 발산할 경우 1에 수렴하고 음의 무한대로 발산할 경우 0에 수렴한다."]},{"cell_type":"markdown","metadata":{"id":"6KxpXKsw--ls"},"source":["### Sigmoid 함수의 입력값(z)이 양의 무한대로 발산하거나 음의 무한대로 발산하는 경우 인공지능 모델의 학습에 어떠한 영향을 미치는지 서술하라.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"if1y8wWj--ls"},"source":["그라디언트 소실 문제가 발생해 제대로된 학습이 불가능해진다."]},{"cell_type":"markdown","metadata":{"id":"uzyVxZef--ls"},"source":["### 아래 제공된 수식은 cross entropy loss에 관한 수식이다. y = [1, 1, 0, 0]이고  $\\hat{y}$은 [1.0, 0.25, 0.875, 0.0]일 때의 loss 값을 구하라.\n","\n","* 아래 수식에서 log의 밑은 2라고 가정한다.\n","$$\n","    loss = - {1 \\over N} \\sum_{n=1}^{N}y_n log\\hat{y}_n + (1- y_n)log (1-\\hat{y}_n)\n","$$"]},{"cell_type":"markdown","metadata":{"id":"QVIDr1uV--ls"},"source":["loss = [0, -log(0.25)=1.3863, -log(0.125)=3.4657, 0]"]},{"cell_type":"markdown","metadata":{"id":"IDmWKlwv--ls"},"source":["### 아래 제공된 두 행렬식의 곱셈 결과를 구하라.\n","\n","$$\n","\n","A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\n","\\qquad\n","B = \\begin{bmatrix} 4 & 3 \\\\ 2 & 1 \\end{bmatrix}\n","$$\n","\n","$$\n","A \\times B = ?\n","$$"]},{"cell_type":"markdown","metadata":{"id":"f2NRU98g--ls"},"source":["\\begin{bmatrix} 8 & 5 \\\\ 20 & 13 \\end{bmatrix}"]},{"cell_type":"markdown","metadata":{"id":"VggTZI4f--lt"},"source":["### 아래 코드의 output을 확인한 후 행렬곱과 완전 연결 신경망(fully-connected layer)의 관계에 대해 서술하라."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Itk_nBi7--lt","executionInfo":{"status":"ok","timestamp":1724145474629,"user_tz":-540,"elapsed":359,"user":{"displayName":"호재류","userId":"13851742628565243579"}},"outputId":"3576cf84-2b45-4e33-a3be-5a1b58e2cb08"},"outputs":[{"output_type":"stream","name":"stdout","text":["A와 B의 행렬 곱 :  tensor([[ 9.,  5.],\n","        [25., 14.]])\n","A를 linear layer W에 통과시킨 output 값 tensor([[ 9.,  5.],\n","        [25., 14.]], grad_fn=<MmBackward0>)\n"]}],"source":["import torch\n","\n","A = torch.Tensor([[1, 2], [3, 5]])\n","B = torch.Tensor([[5, 3], [2, 1]])\n","print(\"A와 B의 행렬 곱 : \", torch.matmul(A, B))\n","\n","W = linear = torch.nn.Linear(2, 2, bias=False)\n","W.weight = torch.nn.Parameter(B.T)\n","print(\"A를 linear layer W에 통과시킨 output 값\", W(A))"]},{"cell_type":"markdown","source":["완전 연결 신경망의 경우 행렬의 곱과 같은 형태로 작동한다."],"metadata":{"id":"DAea_wMZFJf5"}},{"cell_type":"markdown","metadata":{"id":"PI-Rb6_i--lt"},"source":["### BatchSize와 Epoch이 무엇인지 각각 서술하시오."]},{"cell_type":"markdown","metadata":{"id":"Gp2fBuCO--lt"},"source":["BatchSize는 한번의 가중치 업데이트동안 처리되는 데이터 샘플의 수를 의미하고\n","Epoch은 전체 학습 데이터셋이 모델에 완전히 입력되는 횟수를 의미한다."]},{"cell_type":"markdown","metadata":{"id":"VdVuzKE2--lt"},"source":["### 제공된 조건에 맞추어 아래 코드의 빈칸(***)을 채우고 코드가 오류없이 돌아가는지 확인하시오.\n","\n","**조건**\n","* 모델은 4개의 linear layer로 구성되어 있다.\n","* 각 linear layer의 input과 output은 다음과 같다.\n","    * linear1\n","        * input: 1\n","        * output: 3\n","    * linear2\n","        * input: 3\n","        * output: 5\n","    * linear3\n","        * input: 5\n","        * output: 5\n","    * linear4\n","        * input: 5\n","        * output: 1\n","\n","* model의 layer 구성은 다음과 같다.\n","    * linear1 --> relu --> linear2 --> relu --> linear3 --> relu --> linear4"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2wurqAz--lt","executionInfo":{"status":"ok","timestamp":1724145889848,"user_tz":-540,"elapsed":363,"user":{"displayName":"호재류","userId":"13851742628565243579"}},"outputId":"6687cdd4-f908-4421-d611-9a28ec95b9d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model(\n","  (linear1): Linear(in_features=1, out_features=3, bias=True)\n","  (linear2): Linear(in_features=3, out_features=5, bias=True)\n","  (linear3): Linear(in_features=5, out_features=5, bias=True)\n","  (linear4): Linear(in_features=5, out_features=1, bias=True)\n","  (relu): ReLU()\n",")\n","tensor([-0.6726], grad_fn=<ViewBackward0>)\n"]}],"source":["import torch\n","\n","class Model(torch.nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.linear1 = torch.nn.Linear(1, 3)\n","        self.linear2 = torch.nn.Linear(3, 5)\n","        self.linear3 = torch.nn.Linear(5, 5)\n","        self.linear4 = torch.nn.Linear(5, 1)\n","\n","        self.relu = torch.nn.ReLU()\n","    def forward(self, x):\n","        x = self.relu(self.linear1(x))\n","        x = self.relu(self.linear2(x))\n","        x = self.relu(self.linear3(x))\n","        x = self.linear4(x)\n","        return x\n","\n","model = Model()\n","print(model)\n","\n","x = torch.Tensor([1.0])\n","print(model(x))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"V9qrRo6H--lt"},"source":["### DataLoader가 무엇이고 왜 필요한지 서술하시오"]},{"cell_type":"markdown","metadata":{"id":"VtTloxTf--lu"},"source":["DataLoader는 효율적이고 유연한 데이터 관리를 가능하게 하며, 특히 대규모 데이터셋을 처리할 때 필수적인 도구입니다. 이를 통해 모델 학습 과정을 간소화하고, 메모리 관리, 데이터 로딩 속도, 데이터의 다양성 등을 효과적으로 관리할 수 있습니다. DataLoader는 딥러닝 모델의 학습 과정에서 필수적인 구성 요소로 자리잡고 있습니다."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}