{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOfAr2TwmIigEjczO7/V3bQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4DCf5hi0FAe6"},"outputs":[],"source":["import numpy as np\n","\n","def forward(x):\n","    return x*w\n","\n","def loss(x,y):\n","    y_pred = forward(x)\n","    return (y_pred - y)**2\n","x_data = [1.0,2.0,3.0]\n","y_data = [2.0,4.0,6.0]\n","for w in np.arange(0.0,4.1,0.1):\n","    print('w=',w)\n","    l_sum = 0\n","    for x_val,y_val in zip(x_data,y_data):\n","        y_pred_val = forward(x_val)\n","        l = loss(x_val,y_val)\n","        l_sum += l\n","        print('\\t',x_val,y_val,y_pred_val,l)\n","    print('MSE=',l_sum/3)\n"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","w_list=[]\n","mse_list=[]\n","for w in np.arange(0.0,4.1,0.1):\n","    print(f'w={w:.1f}')\n","    l_sum = 0\n","    for x_val,y_val in zip(x_data,y_data):\n","        y_pred_val = forward(x_val)\n","        l = loss(x_val,y_val)\n","        l_sum += l\n","        print('\\t',x_val,y_val,y_pred_val,l)\n","    print(f'MSE={l_sum/3:.2f}')\n","    w_list.append(w)\n","    mse_list.append(l_sum/3)\n","\n","plt.plot(w_list,mse_list)\n","plt.ylabel('Loss')\n","plt.xlabel('w')\n","plt.show()"],"metadata":{"id":"O6-J-3zGNE56"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","x_data = [1.0,2.0,3.0]\n","y_data = [2.0,4.0,6.0]\n","\n","w = 1.0\n","\n","def forward(x):\n","    return x*w\n","\n","def loss(x,y):\n","    y_pred = forward(x)\n","    return (y_pred - y)**2\n","\n","def gradient(x,y):\n","    return 2*x*(x*w-y)\n","\n","print('predict (before training)',4,forward(4))\n","for epoch in range(100):\n","    for x_val,y_val in zip(x_data,y_data):\n","        grad = gradient(x_val,y_val)\n","        w = w - 0.01*grad\n","        print('\\tgrad:',x_val,y_val,grad)\n","        l = loss(x_val,y_val)\n","    print('progress:',epoch,'w=',w,'loss=',l)\n","print('predict (after training)','4hours',forward(4))\n"],"metadata":{"id":"-BvuV_dDNtfs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.autograd import Variable\n","import numpy as np\n","\n","x_data = [1.0,2.0,3.0]\n","y_data = [2.0,4.0,6.0]\n","\n","w = Variable(torch.Tensor([1.0]),requires_grad=True)\n","\n","def forward(x):\n","    return x*w\n","\n","def loss(x,y):\n","    y_pred = forward(x)\n","    return (y_pred - y)**2\n","\n","print('predict (before training)',4,forward(4).data[0])\n","\n","for epoch in range(10):\n","    for x_val,y_val in zip(x_data,y_data):\n","        l = loss(x_val,y_val)\n","        l.backward()\n","        print('\\tgrad:',x_val,y_val,np.array(w.grad.data[0]))\n","        w.data = w.data - 0.01*w.grad.data\n","\n","        w.grad.data.zero_()\n","    print('progress:',epoch,'w=',np.array(w.data[0]),'loss=',np.array(l.data[0]))\n","\n","print('predict (after training)','4hours',np.array(forward(4).data[0]))"],"metadata":{"id":"JWrSEwjoUUfr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"REUNMYSEgQQW"},"execution_count":null,"outputs":[]}]}